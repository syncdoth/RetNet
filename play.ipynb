{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from retnet.configuration_retnet import RetNetConfig\n",
    "from retnet.modeling_retnet import RetNetModel, RetNetModelWithLMHead\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "config = RetNetConfig(decoder_layers=2,\n",
    "                      decoder_embed_dim=8,\n",
    "                      decoder_retention_heads=2,\n",
    "                      decoder_ffn_embed_dim=16)\n",
    "\n",
    "model = RetNetModel(config)\n",
    "model.eval()\n",
    "\n",
    "device = 'cpu'  # cuda, cpu, mps for m1 mac\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "layer: 1\n",
      "True\n",
      "True\n",
      "layer: 2\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.LongTensor([[1,2,1,2]]).to(device)\n",
    "\n",
    "parallel_outputs = model(input_ids, forward_impl='parallel', use_cache=True)\n",
    "parallel_state = parallel_outputs.last_hidden_state\n",
    "parallel_cache = parallel_outputs.past_key_values\n",
    "\n",
    "past_kv = None\n",
    "rnn_state = []\n",
    "for i in range(input_ids.shape[1]):\n",
    "    rnn_out = model(input_ids[:, :i+1], forward_impl='recurrent', past_key_values=past_kv, use_cache=True)\n",
    "    rnn_state.append(rnn_out.last_hidden_state)\n",
    "    past_kv = rnn_out.past_key_values\n",
    "rnn_state = torch.cat(rnn_state, dim=1)\n",
    "rnn_cache = rnn_out.past_key_values\n",
    "\n",
    "\n",
    "chunk_outputs = model(input_ids, forward_impl='chunkwise', use_cache=True, recurrent_chunk_size=2)\n",
    "chunk_state = chunk_outputs.last_hidden_state\n",
    "chunk_cache = chunk_outputs.past_key_values\n",
    "\n",
    "print(torch.allclose(parallel_state, rnn_state, atol=1e-5))\n",
    "# print(torch.allclose(parallel_state, chunk_state, atol=1e-5))\n",
    "\n",
    "for i, (p, r, c) in enumerate(zip(parallel_cache, rnn_cache, chunk_cache)):\n",
    "    print(f\"layer: {i + 1}\")\n",
    "    for key in p.keys():\n",
    "        print(torch.allclose(p[key], r[key], atol=1e-5))\n",
    "        # print(torch.allclose(p[key], c[key], atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "layer: 1\n",
      "True\n",
      "True\n",
      "layer: 2\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.LongTensor([[1,2,3,4,1,2,5,5],\n",
    "                              [5,5,1,2,3,4,1,2]]).to(device)\n",
    "retention_mask = torch.LongTensor([[1,1,1,1,1,1,0,0],\n",
    "                                   [0,0,1,1,1,1,1,1]]).to(device)\n",
    "\n",
    "parallel_outputs = model(input_ids, retention_mask=retention_mask, forward_impl='parallel', use_cache=True)\n",
    "parallel_state = parallel_outputs.last_hidden_state\n",
    "parallel_cache = parallel_outputs.past_key_values\n",
    "\n",
    "past_kv = None\n",
    "rnn_state = []\n",
    "for i in range(input_ids.shape[1]):\n",
    "    rnn_out = model(input_ids[:, :i+1], retention_mask=retention_mask[:, i:i+1], forward_impl='recurrent', past_key_values=past_kv, use_cache=True)\n",
    "    rnn_state.append(rnn_out.last_hidden_state)\n",
    "    past_kv = rnn_out.past_key_values\n",
    "rnn_state = torch.cat(rnn_state, dim=1)\n",
    "rnn_cache = rnn_out.past_key_values\n",
    "\n",
    "\n",
    "chunk_outputs = model(input_ids, retention_mask=retention_mask, forward_impl='chunkwise', use_cache=True, recurrent_chunk_size=4)\n",
    "chunk_state = chunk_outputs.last_hidden_state\n",
    "chunk_cache = chunk_outputs.past_key_values\n",
    "\n",
    "mask = retention_mask.unsqueeze(-1).float()\n",
    "print(torch.allclose(parallel_state * mask, rnn_state * mask, atol=1e-5))\n",
    "# print(torch.allclose(parallel_state * mask, chunk_state * mask, atol=1e-5))\n",
    "\n",
    "for i, (p, r, c) in enumerate(zip(parallel_cache, rnn_cache, chunk_cache)):\n",
    "    print(f\"layer: {i + 1}\")\n",
    "    for key in p.keys():\n",
    "        print(torch.allclose(p[key], r[key], atol=1e-5))\n",
    "        # print(torch.allclose(p[key], c[key], atol=1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    5, 20137, 50121, 14818, 14818, 14818, 14818, 14818, 14818, 14818,\n",
       "          14818, 14818, 14818, 14818, 14818, 14818, 14818, 14818, 14818, 14818,\n",
       "          14818],\n",
       "         [    2,  2622, 14777, 47757, 47757, 47757, 47757, 47757, 47757, 47757,\n",
       "          47757, 47757, 47757, 47757, 47757, 47757, 47757, 47757, 47757, 47757,\n",
       "          47757]]),\n",
       " tensor([[    5, 20137, 50121, 14818, 14818, 14818, 14818, 14818, 14818, 14818,\n",
       "          14818, 14818, 14818, 14818, 14818, 14818, 14818, 14818, 14818, 14818,\n",
       "          14818],\n",
       "         [    2,  2622, 14777, 47757, 47757, 47757, 47757, 47757, 47757, 47757,\n",
       "          47757, 47757, 47757, 47757, 47757, 47757, 47757, 47757, 47757, 47757,\n",
       "          47757]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = RetNetModelWithLMHead(config).to(device)\n",
    "model.eval()\n",
    "\n",
    "p_generated = model.generate(input_ids, parallel_compute_prompt=True, max_new_tokens=20, do_sample=False, early_stopping=False)\n",
    "r_generated = model.generate(input_ids, parallel_compute_prompt=False, max_new_tokens=20, do_sample=False, early_stopping=False)\n",
    "\n",
    "p_generated, r_generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
