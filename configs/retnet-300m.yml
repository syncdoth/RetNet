vocab_size: 50257
decoder_embed_dim: 1280
decoder_value_embed_dim: 2560
decoder_layers: 12
decoder_retention_heads: 8
decoder_ffn_embed_dim: 2560
initializer_range: 0.02
layernorm_eps: 1.0e-6
activation_fn: "gelu"
dropout: 0.0
activation_dropout: 0.0
drop_path_rate: 0.0
decoder_normalize_before: True
layernorm_embedding: True
no_scale_embedding: False
recurrent_chunk_size: 512
use_lm_decay: False
deepnorm: False
subln: True
output_retentions: False
pad_token_id: 50256
eos_token_id: 50256
unk_token_id: 50256
